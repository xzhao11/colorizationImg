{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f516d-56d8-4cf5-b422-725b1e1867f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --user tensorflow==2.8.0\n",
    "! pip install --user numpy\n",
    "! pip install --user tensorflow_datasets\n",
    "! pip install --user matplotlib\n",
    "! pip install --user scikit-image\n",
    "! pip install --user pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd4c740-2c83-4746-954a-cfb26ee54232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import load_img, array_to_img, img_to_array,ImageDataGenerator \n",
    "from skimage import io, color\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32719c2-cdf9-476c-8713-f25ad082e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaced3f-331c-4c01-a1e5-8aebfb49d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessImg(path):\n",
    "    # image = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(path))\n",
    "    # image = np.array(image, dtype=float)\n",
    "    image= io.imread(path)\n",
    "    if image.shape[0] < 360 or image.shape[1] < 360:\n",
    "        return\n",
    "    image = image[0:360,0:360]\n",
    "    rgb = image[:,:,0:3]\n",
    "    # print(rgb.shape[0])\n",
    "    lab = color.rgb2lab(rgb)\n",
    "    # print(lab)\n",
    "    #L channel is the input to network\n",
    "    L = lab[:,:,0]\n",
    "    #A and B channel is the output from network\n",
    "    AB = lab[:,:,1:]\n",
    "    AB /= 128\n",
    "    # print(AB.shape[0], AB.shape[1])\n",
    "    \n",
    "    #reshape L abd AB tensors\n",
    "    #this means a batch of 1 image of shape 400x400\n",
    "    L = L.reshape(360, 360, 1)\n",
    "    AB = AB.reshape(360, 360, 2)\n",
    "    return L, AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c395236-af15-4af3-8516-77dfa2af5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ltrain = []\n",
    "ABtrain = []\n",
    "for filename in os.listdir('input/'):\n",
    "    if os. path. isdir('input/'+filename):\n",
    "        continue\n",
    "    try:\n",
    "        L, AB = preprocessImg('input/'+filename)\n",
    "        Ltrain.append(L)\n",
    "        ABtrain.append(AB)\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f708c3-6f1b-4570-8fa5-85c0240483f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(Ltrain, ABtrain):\n",
    "    # Building the neural network\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(None, None, 1)))\n",
    "    model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))\n",
    "    model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "    model.compile(optimizer='rmsprop',loss='mse')\n",
    "\n",
    "    model.fit(Ltrain, ABtrain, batch_size = 10, epochs=10)\n",
    "    model.save('./tmp/model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416263ad-2d47-4441-b4f8-60c11e4a4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertImg(img, model):\n",
    "    L, AB = preprocessImg(img)\n",
    "    L = L.reshape(1, 360, 360, 1)\n",
    "    # print(L.shape)\n",
    "    output = model.predict(L)\n",
    "    # print(output.shape)\n",
    "    output *= 128\n",
    "    cur = np.zeros((360, 360, 3))\n",
    "    cur[:,:,0] = L[0][:,:,0]\n",
    "    cur[:,:,1:] = output[0]\n",
    "    return cur\n",
    "def saveImg(img, name):\n",
    "    colored = \"output/\" + name + \".png\"\n",
    "    gray = \"output/\" + name + \"_gray.png\"\n",
    "    io.imsave(colored, color.lab2rgb(img))\n",
    "    io.imsave(gray, color.rgb2gray(color.lab2rgb(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6affb6f2-020c-42ff-900b-98368d4955c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"input/\"\n",
    "image1 = \"woman.jpg\"\n",
    "L, AB = preprocessImg(path+image1)\n",
    "\n",
    "Ltrain = np.array(Ltrain, dtype=float)\n",
    "ABtrain = np.array(ABtrain, dtype=float)\n",
    "print(Ltrain.shape)\n",
    "print(ABtrain.shape)\n",
    "try:\n",
    "    loaded_model = tf.keras.models.load_model('./tmp/model')\n",
    "except:\n",
    "    loaded_model = model(Ltrain, ABtrain)\n",
    "# loaded_model.summary()\n",
    "\n",
    "loaded_model = model(Ltrain, ABtrain)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f5e8e4-08a8-4d57-b42a-fe46e7763517",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loaded_model.evaluate(Ltrain, ABtrain, batch_size = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45a8d9-175a-4e27-a1b2-118dc480b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveImg(convertImg('input/woman.jpg', loaded_model), \"woman2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee86c866-1e04-4de4-a1a4-7e3beafe8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('test/'):\n",
    "    if os. path. isdir('test/'+filename):\n",
    "        continue\n",
    "    try:\n",
    "        saveImg(convertImg('test/'+filename, loaded_model), filename)\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
